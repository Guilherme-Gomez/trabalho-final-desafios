---
title: "Desafios e Requisitos dos Projetos Analiticos"
authores: "Davi Almeida Ferreira Juscelino Ribeiro Carvalho e Guilherme Rocha Gomez"
date: "Julho de 2021"
output:
  html_document:
        code_folding: hide
        number_sections: no
        toc: yes
        toc_float:
            collapsed: yes
            smooth_scroll: yes
---
<left>

![](simbolo_fgv.png)

Turma: **FGV TBABD-8**  
Professor: **Rafael Lychowski**  
Autores: **Davi Almeida Ferreira**,
        **Juscelino Ribeiro Carvalho** e
        **Guilherme Rocha Gomez** 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 10, warning = F, error = F)
```


## Metodologia utilizada

Utilizaremos para a realização deste trabalho a metodologia CRISP-DM

<center>

![](crisp-dm.png)

## Entendimento do Negócio

A Vale pretende prever o desgaste de rodas de vagões e fornecer uma visão futura da frota de rodeiros, para melhor planejamento de manutenção e compra de componentes. 

**Problema:** Prever se o friso da roda esta abaixo de 26 mm na próxima leitura.

1. A área não tem visibilidade do que vai contecer com os ativos, antecipando as trocas;
2. A cada troca o rodeiro é usinado, e sua vida útil reduzida;
3. Incapacidade de visualização de desgastes acelerados em toda a frota de vagões
4. Muitos vagões apresentam reinciência de trocas, e os fatores não são bem claros;

* Base de dados: EFC_WAYSIDES.csv
* Variável dependente: ESPESSURA_FRISO_RODA
* Método: Supervisionado
* Submétodo: Classificação
* Objetivo: Identificar quais os frisos terão menos que 26 cm de friso no próximo ciclo.

## Entendimento dos Dados

```{r Configuracao_inicial_bibliotecas, include=FALSE}
# Importar bibliotecas que serão utilizadas no trabalho

#install.packages("rJava")
#install.packages("caret")
#install.packages("mlbench")
#install.packages("tidyverse")
#install.packages("tseries")
#install.packages("ggfortify")
#install.packages("gridExtra")
#install.packages("corrplot")
#install.packages("PerformanceAnalytics")
#install.packages("reshape2")

library(caret)
library(mlbench)
library(dplyr)
library(tidyverse)
library(gridExtra)
library(kableExtra)
library(hrbrthemes)
library(viridis)
library(tseries)
library(ggfortify)
library(corrplot)
library(PerformanceAnalytics)
library(reshape2)

# Iniciar sessão do SPARK
# Separando as mehores configurações para os computadores que cada integrante do grupo usa.

#aluno <- "Guilherme"
#aluno <- "Juscelino"
aluno <- "Davi"

if (aluno == "Guilherme") {

  spark_path <-'C:/Guilherme/spark'
  if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
    Sys.setenv(SPARK_HOME = spark_path)
  }
  library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
  sparkR.session(master = "local[*]", sparkConfig = 
  list(spark.driver.memory = "1g"))
  
  pathfile = "C:/Guilherme/FGV/Desafios e Requisitos dos Projetos Analiticos/EFC_WAYSIDES.csv"

}else if (aluno == "Davi") {
  library(SparkR)
  
  spark_path <-"C:/spark-3.1.2-bin-hadoop3.2"
  if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
    Sys.setenv(SPARK_HOME = spark_path)
  }
  sparkR.session(master = "local[*]", sparkConfig = list(spark.driver.memory = "6g"))
  
  pathfile <- "C:/trabalho-final-desafios/EFC_WAYSIDES.csv"
} else {

  spark_path <-'C:/spark-3.1.2-bin-hadoop3.2'
  if (nchar(Sys.getenv("SPARK_HOME")) < 1) {
    Sys.setenv(SPARK_HOME = spark_path)
  }
  library(SparkR, lib.loc = c(file.path(Sys.getenv("SPARK_HOME"), "R", "lib")))
  sparkR.session(master = "local[*]", sparkConfig = 
  list(spark.driver.memory = "4g"))
  
  pathfile = "C:/Users/jusce/OneDrive/Documents/R/FGV/DesafiosReqProjeAnalit/Aula5/TrabalhoFinal/EFC_WAYSIDES.csv"

}

paste("Configuração para o computador do: ",aluno)

sqlContext <- sparkR.session(sc)
sparkR.conf()

```

```{r Schema, include=FALSE}
# Importar dataset 

# Utilizando o inferSchema muitos campos numéricos foram identificados com string.
schema <- structType(
  structField("ROW_ID", "string"),
  structField("DATA_HORA_LEITURA", "timestamp"),
  structField("CODIGO_VAGAO", "string"),
  structField("CODIGO_RODEIRO", "string"),
  structField("CODIGO_RODA", "string"),
  structField("LADO_RODA", "string"),
  structField("EIXO_VAGAO", "integer"),
  structField("CICLO_RODEIRO", "string"),
  structField("TRAIN_ID", "string"),
  structField("SENTIDO_TREM", "string"),
  structField("VELOCIDADE_ENTRADA_TREM", "double"),
  structField("VELOCIDADE_SAIDA_TREM", "double"),
  structField("POSICAO_VAGAO_COMPOSICAO", "integer"),
  structField("ANGULO_FRISO_RODA", "double"),
  structField("ALTURA_FRISO_RODA", "double"),
  structField("ESPESSURA_FRISO_RODA", "double"),
  structField("CAVA_RODA", "double"),
  structField("ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE", "double"),
  structField("ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE", "double"),
  structField("TRACKING_POSITION_EIXO_FRONTAL_TRUQUE", "double"),
  structField("TRACKING_POSITION_EIXO_TRASEIRO_TRUQUE", "double"),
  structField("ROTACAO_EIXO", "double"),
  structField("ALINHAMENTO_ENTRE_EIXOS_(IAM)", "double"),
  structField("DESLOCAMENTO_ENTRE_EIXOS_(SHIFT)", "double"),
  structField("TRACKING_ERROR_(TE)", "double"),
  structField("SERPENTEAMENTO_(HUNTING)", "double"),
  structField("friso_baixo", "integer"),
  structField("FRISO_MENOR_QUE_26", "integer")
)

df <- SparkR::read.df(path = pathfile,
                      header='true', 
                      source = "com.databricks.spark.csv", 
                      schema = schema,
                      na.strings = "")

head(df)
cache(df)

# Retirando os parenteses das variáveis (Todas)
# colnames(df) <- df %>% colnames() %>% gsub("\\s*\\([^\\)]+\\)","",.)
df <- withColumnRenamed(df, "ALINHAMENTO_ENTRE_EIXOS_(IAM)", "ALINHAMENTO_ENTRE_EIXOS_IAM")
df <- withColumnRenamed(df, "DESLOCAMENTO_ENTRE_EIXOS_(SHIFT)", "DESLOCAMENTO_ENTRE_EIXOS_SHIFT")
df <- withColumnRenamed(df, "TRACKING_ERROR_(TE)", "TRACKING_ERROR_TE")
df <- withColumnRenamed(df, "SERPENTEAMENTO_(HUNTING)", "SERPENTEAMENTO_HUNTING")

colnames(df)

#Criando novas colunas pelo método mais comum.
df$FRISO_BAIXO <- SparkR::ifelse(df$ESPESSURA_FRISO_RODA<26,1,0)

#Criando novas colunas pelo método mais comum.
df$FRISO_MENOR_QUE_26 <- SparkR::ifelse(df$ESPESSURA_FRISO_RODA<26,"YES","NO")

#Criando novas colunas e escolhendo o tipo de dado usanod withColumn.
df <- df %>% 
  withColumn(.,"DIA",cast(df$DATA_HORA_LEITURA,"Date")) #%>% 
  #withColumn(.,"Dia",cast(df$DATA_HORA_LEITURA,"Date"))


df_sample <- df %>% sample(withReplacement = F,fraction = 0.0005)


#Criando vetores com os nomes das colunas para os tipos texto e número.
colunas_numeric <- cbind(coltypes(df),colnames(df)) %>%
as.data.frame %>%
dplyr::filter(.$V1=="numeric") %>%
dplyr::select(medidas=V2)

colunas_text <- cbind(coltypes(df),colnames(df)) %>%
as.data.frame %>%
dplyr::filter(.$V1!="numeric") %>%
dplyr::select(medidas=V2)

#read.df(sqlContext,)

# Incluir o arquivo na memória para facilitar a interação
persist(df,"MEMORY_ONLY")

#cache(df) == persist(df,"MEMORY_ONLY")
#cacheTable(sqlContext,"tableNmae")

```

### Verificação da qualidade dos Dados

Verificando o 'Schema' dos dados
```{r Mostrando_Schema}
#Verificando o 'Schema' dos dados"
printSchema(df)

```

Criando uma amostra dos dados (1%) para utilização em análises

```{r Sample, cache=TRUE}
nrowdf <- nrow(df)
#nrowdf

df_sample <- df %>% sample(withReplacement = F,fraction = 0.01)

nrowdf_s <- nrow(df_sample)
#nrowdf_s

print(paste("Utilizamos uma amostra de ",round((nrowdf_s*100/nrowdf),2),"% de dados",sep=""))
```

### Verificar a existencia de dados faltantes

```{r Vericacao_da_qualidade_dos_dados, cache=TRUE}

#Verificando qualidade dos dados.

test_null <- function(data_frame,coluna){
   try(data_frame %>% where(.,isNull(.[[coluna]]))%>%count(.), silent = TRUE)}

test_isNAN <- function(data_frame,coluna){
  try(data_frame %>% where(.,isNaN(.[[coluna]]))%>%count(.), silent = TRUE)}

test_vazio <- function(data_frame,coluna){
  try(data_frame %>% where(.,.[[coluna]]== "")  %>% count(.), silent = TRUE)}

test_zero <- function(data_frame,coluna){
  try(data_frame %>% where(.,.[[coluna]]== 0)  %>% count(.), silent = TRUE)}

total <- count(df)

class(df$ROW_ID)

x <- 0
Tipo_de_dados <- 0

# Criando a coluna de tipo de dados
for (i in 1:length(colnames(df))){
  x[i] <- dtypes(df)[[i]][1]
  Tipo_de_dados[i] <- dtypes(df)[[i]][2]
}
tipo_dados <- as.data.frame(Tipo_de_dados,x)

cont_prob <- data.frame()
for (coluna in colnames(df)){
#As colunas no dataframe serão linhas neste relatório.
  
  cont_prob[coluna,"Nulo"] <- test_null(df,coluna)
  cont_prob[coluna,"Nulo"] <- ifelse(is.numeric(cont_prob[coluna,"Nulo"]),
                                      cont_prob[coluna,"Nulo"], 0)
  cont_prob[coluna,"% Nulo"]  <- ifelse(is.numeric(cont_prob[coluna,"Nulo"]), paste(round(((cont_prob[coluna,"Nulo"]/total)*100),2),"%",sep=""), "0%")
  
  cont_prob[coluna,"isNAN"] <- test_isNAN(df,coluna)
  cont_prob[coluna,"isNAN"] <- ifelse(is.numeric(cont_prob[coluna,"isNAN"]),
                                      cont_prob[coluna,"isNAN"], 0)
  cont_prob[coluna,"% isNAN"] <- ifelse(is.numeric(cont_prob[coluna,"isNAN"]), paste(round(((cont_prob[coluna,"isNAN"]/total)*100),2),"%",sep=""), "0%")
  
  cont_prob[coluna,"Vazio"] <- test_vazio(df,coluna)
  cont_prob[coluna,"Vazio"] <- ifelse(is.numeric(cont_prob[coluna,"Vazio"]),
                                      cont_prob[coluna,"Vazio"], 0)
  
  cont_prob[coluna,"% Vazio"] <- ifelse(is.numeric(cont_prob[coluna,"Vazio"]), paste(round(((cont_prob[coluna,"Vazio"]/total)*100),2),"%",sep=""), "0%")

  cont_prob[coluna,"Zero"]  <- test_zero(df,coluna)
  cont_prob[coluna,"Zero"]  <- ifelse(is.numeric(cont_prob[coluna,"Zero"]),
                                      cont_prob[coluna,"Zero"],0)
  
  cont_prob[coluna,"% Zero"] <- ifelse(is.numeric(cont_prob[coluna,"Zero"]), paste(round(((cont_prob[coluna,"Zero"]/total)*100),2),"%",sep=""), "0%")
  
}

cont_prob <- cbind(cont_prob,tipo_dados)

cont_prob %>% kable(., format = "html",row.names = T, digits = 2) %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed","responsive")) 
```

### Avaliando os dados nulos

#### CAVA_RODA, ANGULO_FRiSO_RODA 

CAVA_RODA: A variável com maior número de dados nulos foi a CAVA_RODA com 607.049 (20%) de dados nulos. Com o objetivo de avaliar a estratégia de tratamento dos dados vamos realizar a distribuição de dados nulos em comparação com as outras variáveis.

ANGULO_FRISO_RODA: A segunda variável com maior número de dados nulos foi a ANGULO_FRISO_RODA com 287.408 (10%) dados nulos em comparação as outras variáveis.

```{r Avaliacao_CAVA_RODA_ANGULO_FRISO}

# Avaliando os dados nulos para CAVA_RODA, indentificando se ocorreu alguma data com maior numero de dados nulos.

df_null_CAVA_RODA <- where(df, isNull(df$CAVA_RODA))

nulos_CAVA_RODA <- count(df_null_CAVA_RODA)

perc_nulos_CAVA_RODA <- paste(round((nulos_CAVA_RODA/total)*100,0),"%",sep="")

#perc_nulos_CAVA_RODA

# Avaliando os dados nulos para ANGULO_FRiSO_RODA, indentificando se ocorreu alguma data com maior numero de dados nulos.

df_null_ANGULO_FRISO_RODA <- where(df, isNull(df$ANGULO_FRISO_RODA))

nulos_ANGULO_FRISO_RODA <- count(df_null_ANGULO_FRISO_RODA)

perc_nulos_ANGULO_FRISO_RODA <- paste(round((nulos_ANGULO_FRISO_RODA/total)*100,0),"%",sep="")

#perc_nulos_ANGULO_FRISO_RODA

# O percentual de dados faltando para CAVA_RODA é de 20%

gb_df_null_CAVA_RODA <- groupBy(df_null_CAVA_RODA, df_null_CAVA_RODA$DIA)

nNull_CAVA_RODA_by_DIA <- agg(gb_df_null_CAVA_RODA, Nulls_CAVA_RODA = n(df_null_CAVA_RODA$Dia))

nNull_CAVA_RODA_by_DIA.dat <- collect(nNull_CAVA_RODA_by_DIA)
#nNull_CAVA_RODA_by_DIA.dat

CAVA_RODA_order_by_date <- nNull_CAVA_RODA_by_DIA.dat[order(nNull_CAVA_RODA_by_DIA.dat$DIA),]
#CAVA_RODA_order_by_date

# O percentual de dados faltando para ANGULO_FRISO_RODA é de 10%

gb_df_null_ANGULO_FRISO_RODA <- groupBy(df_null_ANGULO_FRISO_RODA, df_null_ANGULO_FRISO_RODA$DIA)

nNull_ANGULO_FRISO_RODA_by_DIA <- agg(gb_df_null_ANGULO_FRISO_RODA, 
                                      Nulls_ANGULO_FRISO_RODA = n(df_null_ANGULO_FRISO_RODA$Dia))

nNull_ANGULO_FRISO_RODA_by_DIA.dat <- collect(nNull_ANGULO_FRISO_RODA_by_DIA)
#nNull_ANGULO_FRISO_RODA_by_DIA.dat

ANGULO_FRISO_RODA_order_by_date <- nNull_ANGULO_FRISO_RODA_by_DIA.dat[order(nNull_ANGULO_FRISO_RODA_by_DIA.dat$DIA),]
#ANGULO_FRISO_RODA_order_by_date

full <- full_join(CAVA_RODA_order_by_date,
                  ANGULO_FRISO_RODA_order_by_date,
                  by = NULL)
#full

# Gráfico de Full

g_full <- ggplot(full, aes(x=DIA))+
  geom_line(aes(y=Nulls_CAVA_RODA),color="green")+
  geom_line(aes(y=Nulls_ANGULO_FRISO_RODA),color="red")+
  ggtitle("Nulos nas variáveis por dia")+
  xlab("Data (dias)")+
  ylab("Total de Nulos")+
  theme_dark()
g_full
# Incluir no gráfico a linha de total de dados

```


```{r eval=FALSE, include=FALSE}
sdf_date <-summarize(groupBy(df_clean, df_clean$DIA), count = n(df_clean$ROW_ID)) 

sdf_date <- collect(sdf_date)

sdf_date <- sdf_date[order(sdf_date$DIA),]


head(sdf_date)
g_date <- ggplot(sdf_date, aes(x=DIA))+
  geom_line(aes(y=count),color="green")+
  ggtitle("Qntd de dados DIA")+
  xlab("Data (DIAs)")+
  ylab("Total de dados")+
  theme_dark()
g_date
```


Percebe-se um aumento significativo no número de dados nulos no final do período.

#### ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE, ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE, TRACKING_POSITION_EIXO_FRONTAL_TRUQUE, TRACKING_POSITION_EIXO_TRASEIRO_TRUQUE, ROTACAO_EIXO, ALINHAMENTO_ENTRE_EIXOS_(IAM), DESLOCAMENTO_ENTRE_EIXOS_(SHIFT) e TRACKING_ERROR_(TE)

Essas variáveis apresentam 19.723 (1%) de valores nulos

```{r Avaliacao_dados_TBOGIE}

# Avaliando os dados nulos para CAVA_RODA, indentificando se ocorreu alguma data com maior numero de dados nulos.

variaveis <- c("ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE",
"ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE",
"TRACKING_POSITION_EIXO_FRONTAL_TRUQUE",
"TRACKING_POSITION_EIXO_TRASEIRO_TRUQUE",
"ROTACAO_EIXO", 
"ALINHAMENTO_ENTRE_EIXOS_IAM", 
"DESLOCAMENTO_ENTRE_EIXOS_SHIFT", 
"TRACKING_ERROR_TE")

#ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE
# Avaliando os dados nulos para ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE, indentificando se ocorreu alguma data com maior numero de dados nulos.

df_null_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE <- where(df, isNull(df$ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE))

nulos_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE <- count(df_null_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE)

# O percentual de dados faltando para ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE é de 1%

gb_df_null_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE <- groupBy(df_null_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE, df_null_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE$DIA)

nNull_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE_by_DIA <- agg(gb_df_null_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE, Nulls_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE = n(df_null_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE$DIA))

nNull_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE_by_DIA.dat <- collect(nNull_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE_by_DIA)
#nNull_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE_by_DIA.dat

ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE_order_by_date <- nNull_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE_by_DIA.dat[order(nNull_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE_by_DIA.dat$DIA),]
#ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE_order_by_date

# Avaliando os dados nulos para ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE, indentificando se ocorreu alguma data com maior numero de dados nulos.

df_null_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE <- where(df, isNull(df$ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE))

nulos_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE <- count(df_null_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE)

# O percentual de dados faltando para ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE é de 20%

gb_df_null_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE <- groupBy(df_null_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE, df_null_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE$DIA)

nNull_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE_by_DIA <- agg(gb_df_null_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE, Nulls_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE = n(df_null_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE$DIA))

nNull_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE_by_DIA.dat <- collect(nNull_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE_by_DIA)
#nNull_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE_by_DIA.dat

ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE_order_by_date <- nNull_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE_by_DIA.dat[order(nNull_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE_by_DIA.dat$DIA),]
#ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE_order_by_date

# Avaliando os dados nulos para TRACKING_POSITION_EIXO_FRONTAL_TRUQUE, indentificando se ocorreu alguma data com maior numero de dados nulos.

df_null_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE <- where(df, isNull(df$TRACKING_POSITION_EIXO_FRONTAL_TRUQUE))

# O percentual de dados faltando para TRACKING_POSITION_EIXO_FRONTAL_TRUQUE é de 20%

gb_df_null_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE <- groupBy(df_null_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE, df_null_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE$DIA)

nNull_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE_by_DIA <- agg(gb_df_null_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE, Nulls_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE = n(df_null_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE$DIA))

nNull_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE_by_DIA.dat <- collect(nNull_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE_by_DIA)
#nNull_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE_by_DIA.dat

TRACKING_POSITION_EIXO_FRONTAL_TRUQUE_order_by_date <- nNull_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE_by_DIA.dat[order(nNull_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE_by_DIA.dat$DIA),]
#TRACKING_POSITION_EIXO_FRONTAL_TRUQUE_order_by_date

full <- full_join(ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE_order_by_date,
                  ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE_order_by_date,
                  by = NULL)

full <- full_join(full,
                  TRACKING_POSITION_EIXO_FRONTAL_TRUQUE_order_by_date,
                  by= NULL)

g_full <- ggplot(full, aes(x=DIA))+
  geom_line(aes(y=Nulls_ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE),color="green")+
  geom_line(aes(y=Nulls_ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE),color="red")+
  geom_line(aes(y=Nulls_TRACKING_POSITION_EIXO_FRONTAL_TRUQUE),color="blue")+
  ggtitle("Nulos nas variáveis AAEFT, AAETT e TPEFT por DIA")+
  xlab("Data (DIAs)")+
  ylab("Total de Nulos")+
  theme_dark()
g_full

```

Essas variaveis todas apresentaram um comportamento igual, ou seja, todas os casos nulos ocorreram no mesmo periodo, como todos essas dados são do T-BOGIE, acreditamos que ocorreu uma falha nesse sistema de medição nesses períodos.

### Realizando limpeza dos dados

```{r Limpeza_dados}

#Limpando os dados nulos das colunas
#colnames(df)

dim(df)[1] %>% paste("Total de dados da base original ",.,sep="") %>% print()

# Retirando os dados nulos de CAVA_RODA (20.46% da base)
df_clean <- df %>% where(.,!isNull(.[[17]]))
# Retirando os dados nulos de ANGULO_FRISO_RODA (9.69% da base)
df_clean <- df_clean %>% where(.,!isNull(.[[14]]))
# Retirando os dados nulos de ESPESSURA_FRISO_RODA (0.05% da base)
df_clean <- df_clean %>% where(.,!isNull(.[[16]]))
# Retirando os dados nulos de ALTURA_FRISO_RODA (0.01% da base)
df_clean <- df_clean %>% where(.,!isNull(.[[15]]))
# Retirando os dados nulos de TRACKING_ERROR_(TE) (0.21% da base)
df_clean <- df_clean %>% where(.,!isNull(.[[25]]))

dim(df_clean)[1] %>% paste("Total de dados da base limpa ",.,sep="") %>% print()

# Redução dos dados
reduc <- round(((dim(df_clean)[1]/dim(df)[1])-1)*100,2) 
reduc <- paste("Redução dos dados de ",-reduc,"%",sep="")
print(reduc)

# Criando a coluna de tipo de dados
for (i in 1:length(colnames(df_clean))){
  x[i] <- dtypes(df_clean)[[i]][1]
  Tipo_de_dados[i] <- dtypes(df_clean)[[i]][2]
}
tipo_dados <- as.data.frame(Tipo_de_dados,x)

cont_clean <- data.frame()
for (coluna in colnames(df_clean)){

    cont_clean[coluna,"Nulo"] <- test_null(df_clean,coluna)
  cont_clean[coluna,"Nulo"] <- ifelse(is.numeric(cont_clean[coluna,"Nulo"]),
                                      cont_clean[coluna,"Nulo"], 0)
  cont_clean[coluna,"% Nulo"]  <- ifelse(is.numeric(cont_clean[coluna,"Nulo"]), paste(round(((cont_clean[coluna,"Nulo"]/total)*100),2),"%",sep=""), "0%")
  
  cont_clean[coluna,"isNAN"] <- test_isNAN(df_clean)
  cont_clean[coluna,"isNAN"] <- ifelse(is.numeric(cont_clean[coluna,"isNAN"]),
                                      cont_clean[coluna,"isNAN"], 0)
  cont_clean[coluna,"% isNAN"] <- ifelse(is.numeric(cont_clean[coluna,"isNAN"]), paste(round(((cont_clean[coluna,"isNAN"]/total)*100),2),"%",sep=""), "0%")
  
  cont_clean[coluna,"Vazio"] <- test_vazio(df_clean,coluna)
  cont_clean[coluna,"Vazio"] <- ifelse(is.numeric(cont_clean[coluna,"Vazio"]),
                                      cont_clean[coluna,"Vazio"], 0)
  
  cont_clean[coluna,"% Vazio"] <- ifelse(is.numeric(cont_clean[coluna,"Vazio"]), paste(round(((cont_clean[coluna,"Vazio"]/total)*100),2),"%",sep=""), "0%")

  cont_clean[coluna,"Zero"]  <- test_zero(df_clean,coluna)
  cont_clean[coluna,"Zero"]  <- ifelse(is.numeric(cont_clean[coluna,"Zero"]),
                                      cont_clean[coluna,"Zero"],0)
  
  cont_clean[coluna,"% Zero"] <- ifelse(is.numeric(cont_clean[coluna,"Zero"]), paste(round(((cont_clean[coluna,"Zero"]/total)*100),2),"%",sep=""), "0%")
  
}

cont_clean <- cbind(cont_clean,tipo_dados)

cont_clean %>% kable(., format = "html",row.names = T, digits = 2) %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed","responsive")) 

df_sample_clean <- df_clean %>% sample(withReplacement = F,fraction = 0.01)

```

### Identificar as principais estatisticas da Amostra

```{r Indicadores_da_amostra}
#Principais indicadores.

resumo_medidas <- data.frame()
resultado <- data.frame()

for (coluna in colunas_numeric$medidas){
#As colunas no dataframe são linhas neste relatório
#utilizando os dados de amostras (samples) para ser mais ágil.
resultado <- cbind(coluna,
df_clean %>% agg(.,
media = avg(.[[coluna]]),
desvio_padrao = sd(.[[coluna]]),
variancia = var(.[[coluna]]),
maximo = max(.[[coluna]]),
minimo = min(.[[coluna]])) %>%
as.data.frame())
resumo_medidas <- rbind(resumo_medidas,resultado)
}

#Print da tabela resumo.
resumo_medidas %>% kable(., format = "html",row.names = T, digits = 2) %>%
kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))


#Usando agg com agregação
# gb_sn <- groupBy(df_sample, df_sample$CODIGO_RODA)
# df2 <- agg(gb_sn, friso_avg = avg(df_sample$ESPESSURA_FRISO_RODA), count = n(df_sample$ESPESSURA_FRISO_RODA))
# head(df2)

```

Indentificamos que todas as variáveis possuem valor máximo e minimo, dentro dos limites esperados.

### Visualizações

#### Principais correlações entre os dados numéricos

```{r Correlacao_entre_variaveis, cache=TRUE}
# Medindo a correlação entre ESPESSURA FRISO RODA E EIXO VAGAO
#dim(df_clean)

df_numeric <- select(df_sample_clean,
                     "ESPESSURA_FRISO_RODA",
                      "VELOCIDADE_ENTRADA_TREM",
                     "VELOCIDADE_SAIDA_TREM",
                     "ANGULO_FRISO_RODA",
                     "ALTURA_FRISO_RODA",
                     "CAVA_RODA",
                     "ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE",
                     "ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE",
                     "TRACKING_POSITION_EIXO_FRONTAL_TRUQUE",
                     "TRACKING_POSITION_EIXO_TRASEIRO_TRUQUE",
                     "ROTACAO_EIXO",
                     "ALINHAMENTO_ENTRE_EIXOS_IAM",
                     "DESLOCAMENTO_ENTRE_EIXOS_SHIFT",
                     "TRACKING_ERROR_TE") %>% 
                       collect(.)


colnames(df_numeric) <- c("ESP_FR",
                          "VEL_ET",
                           "VEL_ST",
                           "ANG_FR",
                           "ANG_FR",
                           "CAV_R",
                           "ANG_AEFT",
                           "ANG_AETT",
                           "TR_PEFT",
                           "TR_PETT",
                           "ROT_E",
                           "ALI_EE",
                           "DES_EE",
                           "TR_ER")

chart.Correlation(df_numeric, histogram=TRUE, pch=19)

#cor(sdf_numeric)

cormat <- round(cor(df_numeric),2)
#cormat

# Melt the correlation matrix
melted_cormat <- melt(cormat)
melted_cormat

# Create a ggheatmap
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "light green", high = "red", mid = "yellow", 
                       midpoint = 0.5, limit = c(0,1), space = "Lab", 
                       name="Pearson\nCorrelation") +
  theme_minimal()+ # minimal theme
  theme(axis.text.x = element_text(angle = 90, vjust = 1, 
                                   size = 12, hjust = 1))+
  coord_fixed()

# Outra visão da correlação. 
ggheatmap + 
  labs(title = "Mapa de correlação das variaveis")+
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
  theme(
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.ticks = element_blank(),
    plot.title = element_text(hjust = 0.5))

```
ESP_FR - ESPESSURA_FRISO_RODA

VEL_ET - VELOCIDADE_ENTRADA_TREM

VEL_ST - VELOCIDADE_SAIDA_TREM

ANG_FR - ANGULO_FRISO_RODA

ALT_FR - ALTURA_FRISO_RODA

CAV_R - CAVA_RODA

ANG_AEFT - ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE

ANG_AETT - ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE

TR_PEFT - TRACKING_POSITION_EIXO_FRONTAL_TRUQUE

TR_PETT - TRACKING_POSITION_EIXO_TRASEIRO_TRUQUE

ROT_E - ROTACAO_EIXO

ALI_EE - ALINHAMENTO_ENTRE_EIXOS_(IAM)

DES_EE - DESLOCAMENTO_ENTRE_EIXOS_(SHIFT)

TR_ER - TRACKING_ERROR_(TE)")



### BoxPlot {.tabset .tabset-fade .tabset-pills}

* É possível notar um grande aumento no volume de dados e uma menor variância nos dados após o mês de Abril de 2018.  

* O tamanho das composições aumentam na mesma data.
    + Cada lote são 110 vagões, sendo em média 3 lotes.

#### Friso Mensal

Criando tabelas auxiliares para geração de visualizações

```{r Box_plot_mes, message=FALSE, warning=FALSE}

createOrReplaceTempView(df, "tabela")
sdf_vagao_trocas_roda_all <- sql(
"
  select
    *
  from
  tabela
  
  where CODIGO_VAGAO in
  (
  select
    CODIGO_VAGAO
    
      from tabela
    where CODIGO_RODA != CICLO_RODEIRO
          and
          CODIGO_VAGAO in 
              (select
                  CODIGO_VAGAO
                      from tabela
                    where FRISO_BAIXO ==1
                    group by CODIGO_VAGAO)


    group by CODIGO_VAGAO
  )
    "
)


sdf_vagao_trocas_roda_all %>% 
 withColumn("mes_ano",date_trunc("month",.$DIA)) %>%
 collect(.) %>% 
 ggplot( aes(x=as.factor(mes_ano), y=ESPESSURA_FRISO_RODA, fill=as.factor(mes_ano))) +
   geom_boxplot() +
   scale_fill_viridis(discrete = TRUE, alpha=0.6) +
   geom_jitter(color="black", size=0.001, alpha=0.01) +
   theme(
     legend.position="none",
     plot.title = element_text(size=11)
   ) +
   #scale_y_continuous(limits = c(0,100))+
   ggtitle("Comportamento espessura do friso por Mês") +
   xlab("")+
   ylab("Milímetros")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  geom_hline(yintercept=26, linetype="dashed", color = "red", size=1)
```

#### Friso Semanal

```{r Box_plot_semana, message=FALSE, warning=FALSE}
sdf_vagao_trocas_roda_all %>% 
 withColumn("semana_ano",date_trunc("week",.$DIA)) %>%
 collect(.) %>% 
 ggplot( aes(x=as.factor(semana_ano), y=ESPESSURA_FRISO_RODA, fill=as.factor(semana_ano))) +
   geom_boxplot() +
   scale_fill_viridis(discrete = TRUE, alpha=0.6) +
   geom_jitter(color="black", size=0.005, alpha=0.01) +
   theme(
     legend.position="none",
     plot.title = element_text(size=11)
   ) +
   #scale_y_continuous(limits = c(0,100))+
   ggtitle("Comportamento espessura do friso por Semana") +
   xlab("")+
   ylab("Milímetros")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+
  geom_hline(yintercept=26, linetype="dashed", color = "red", size=1)
```


#### Dim Lote Mensal

```{r Box_plot_dim_mes, message=FALSE, warning=FALSE}
createOrReplaceTempView(df, "tabela")

sql(
  "
select TRAIN_ID, dia, count(*) qtd from
      (
        select TRAIN_ID, CODIGO_VAGAO, dia 
        from tabela 
        group by TRAIN_ID, CODIGO_VAGAO, dia
      ) 
group by TRAIN_ID, dia
  "
  ) %>% 
 withColumn("mes_ano",date_trunc("month",.$DIA)) %>%
 collect(.) %>% 
 ggplot( aes(x=as.factor(mes_ano), y=qtd, fill=as.factor(mes_ano))) +
   geom_boxplot() +
   scale_fill_viridis(discrete = TRUE, alpha=0.6) +
   geom_jitter(color="black", size=0.001, alpha=0.01) +
   theme(
     legend.position="none",
     plot.title = element_text(size=11)
   ) +
   #scale_y_continuous(limits = c(0,100))+
   ggtitle("Tamanho das composições") +
   xlab("")+
   ylab("Qtd")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  #geom_hline(yintercept=26, linetype="dashed", color = "red", size=1)
  
  

```


#### Dim Lote Semanal

```{r Box_plot_dim_semana, message=FALSE, warning=FALSE}
createOrReplaceTempView(df, "tabela")

sql(
  "
select TRAIN_ID, dia, count(*) qtd from
      (
        select TRAIN_ID, CODIGO_VAGAO, dia 
        from tabela 
        group by TRAIN_ID, CODIGO_VAGAO, dia
      ) 
group by TRAIN_ID, dia
  "
  ) %>% 
 withColumn("semana_ano",date_trunc("week",.$DIA)) %>%
 collect(.) %>% 
 ggplot( aes(x=as.factor(semana_ano), y=qtd, fill=as.factor(semana_ano))) +
   geom_boxplot() +
   scale_fill_viridis(discrete = TRUE, alpha=0.6) +
   geom_jitter(color="black", size=0.001, alpha=0.01) +
   theme(
     legend.position="none",
     plot.title = element_text(size=11)
   ) +
   #scale_y_continuous(limits = c(0,100))+
   ggtitle("Tamanho das composições") +
   xlab("")+
   ylab("Qtd")+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  #geom_hline(yintercept=26, linetype="dashed", color = "red", size=1)
  
  

```



### Abertura Históricos Cenário 1 {.tabset .tabset-fade .tabset-pills}


Criando visualizações temporais dos casos de maior destaque onde os trens (TRAIN ID) apresentaram o maior volume de rodas com friso baixo.

```{r echo=FALSE, message=FALSE, warning=FALSE}
#Criando tabela temporária com dados totais
createOrReplaceTempView(df, "tabela")
#Criando tabela temporária com dados apenas de roda com friso baixo.
createOrReplaceTempView(where(df,df$FRISO_MENOR_QUE_26=="YES"), "tabela_FRISO_BAIXO")

# Lista os vagões com maior número de rodas com friso baixo da lista dos trens que acumularam o maior número de rodas com friso baixo.
sdf_worst_vagoes_worst_train <- sql("
    select CODIGO_VAGAO,count(*) qtd from tabela
      where TRAIN_ID IN
          (
              select TRAIN_ID from 
              (
                select  TRAIN_ID ,count(*) qtd
                     from tabela_FRISO_BAIXO
                     group by TRAIN_ID
                order by qtd desc
                limit 5
              )
          )
          and
       FRISO_MENOR_QUE_26='YES'
     group by CODIGO_VAGAO
     order by qtd desc
    limit 5
")



vagoes <- sdf_worst_vagoes_worst_train %>% head() %>% as.list()

myplots <- list()
n <- 1
for (vagao in vagoes$CODIGO_VAGAO){
  filtro_vagao <- vagao
  g1 <- 
    where(df,df$CODIGO_VAGAO==filtro_vagao)  %>%
    collect() %>%
    ggplot(aes(x=DIA, y=ESPESSURA_FRISO_RODA,color=CICLO_RODEIRO))+
    geom_point()+facet_wrap(~CODIGO_RODA,ncol = 2)+
    scale_y_continuous(limits = c(18,38))+
    geom_smooth()+
    geom_hline(yintercept=26, linetype="dashed", color = "red", size=1)+
    theme(legend.position="none")
  
  myplots[[n]] <- g1
  n <- n+1
  
}

```



#### Vagão_1

```{r echo=FALSE, message=FALSE, warning=FALSE}
myplots[[1]]
```

#### Vagão_2

```{r echo=FALSE, message=FALSE, warning=FALSE}
myplots[[2]]
```

#### Vagão_3

```{r echo=FALSE, message=FALSE, warning=FALSE}
myplots[[3]]
```

#### Vagão_4

```{r echo=FALSE, message=FALSE, warning=FALSE}
myplots[[4]]
```

#### Vagão_5

```{r echo=FALSE, message=FALSE, warning=FALSE}
myplots[[5]]
```


```{r eval=FALSE, include=FALSE}

### Não rodar no knit. Apenas pAra exportar CSV

# Histórico dos vagões que estavam nos trens (TRAIN ID) com maior volume FRISOS BAIXOS.
hist_vagoes_piores_trens <- sql("
  
select * from tabela

where CODIGO_VAGAO in
  (
    select CODIGO_VAGAO from tabela
      where TRAIN_ID IN
          (
              select TRAIN_ID from 
              (
                select  TRAIN_ID ,count(*) qtd
                     from tabela_FRISO_BAIXO
                     group by TRAIN_ID
                order by qtd desc
                limit 5
              )
          )
     group by CODIGO_VAGAO
  )
")

hist_vagoes_piores_trens %>% collect() %>% write.csv("vagoes_piores_trens.csv")
```



### Abertura Históricos Cenário 2 {.tabset .tabset-fade .tabset-pills}

Criando visualizações temporais dos casos de maior destaque para os vagões que apresentaram o maior volume de trocas de rodeiros.

```{r echo=FALSE, message=FALSE, warning=FALSE}

createOrReplaceTempView(df, "tabela")

sdf_worst_vagoes <- sql(
"
  select
    CODIGO_VAGAO,
    count(*) qtd
   from  tabela

  where CODIGO_RODA in
    (
      select
          CODIGO_RODA
          from tabela
        where ROW_ID == CICLO_RODEIRO
    ) and
    FRISO_MENOR_QUE_26='YES'
    
    group by CODIGO_VAGAO
    order by qtd desc

    limit 5
"
)


vagoes <- sdf_worst_vagoes %>% head() %>% as.list()

myplots <- list()
n <- 1
for (vagao in vagoes$CODIGO_VAGAO){
  filtro_vagao <- vagao
  g1 <- 
    where(df,df$CODIGO_VAGAO==filtro_vagao)  %>%
    collect() %>%
    ggplot(aes(x=DIA, y=ESPESSURA_FRISO_RODA,color=CICLO_RODEIRO))+
    geom_point()+facet_wrap(~CODIGO_RODA,ncol = 2)+
    scale_y_continuous(limits = c(18,38))+
    geom_smooth()+
    geom_hline(yintercept=26, linetype="dashed", color = "red", size=1)+
    theme(legend.position="none")
  
  myplots[[n]] <- g1
  n <- n+1
  
}

```


#### Vagão_1

```{r echo=FALSE, message=FALSE, warning=FALSE}
myplots[[1]]
```

#### Vagão_2

```{r echo=FALSE, message=FALSE, warning=FALSE}
myplots[[2]]
```

#### Vagão_3

```{r echo=FALSE, message=FALSE, warning=FALSE}
myplots[[3]]
```

#### Vagão_4

```{r echo=FALSE, message=FALSE, warning=FALSE}
myplots[[4]]
```

#### Vagão_5

```{r echo=FALSE, message=FALSE, warning=FALSE}
myplots[[5]]
```




```{r eval=FALSE, include=FALSE}

#Trem com o maior número de rodas com o friso baixo.
createOrReplaceTempView(where(df,df$TRAIN_ID=='25B7F2F33'), "tabela_pior_trem")

# createOrReplaceTempView(where(df,df$TRAIN_ID=='25B2621FD'), "tabela_pior_trem")
# createOrReplaceTempView(where(df,df$TRAIN_ID=='25B2F0558'), "tabela_pior_trem")
# createOrReplaceTempView(where(df,df$TRAIN_ID=='25B3A93CC'), "tabela_pior_trem")

vagoes <- sql("
              select CODIGO_VAGAO,DIA
              from tabela_pior_trem 
              group by CODIGO_VAGAO,DIA
              order by CODIGO_VAGAO,DIA desc") %>% collect()

#Criando uma tabela com os dados dos vagões que estavam no trem que teve o maior número de rodas com friso baixo (considerando o pior trêm).

createOrReplaceTempView(where(df,df$CODIGO_VAGAO %in% vagoes$CODIGO_VAGAO), "tabela_vagoes_do_pior_trem")

tabela_all <- sql("select * from tabela_vagoes_do_pior_trem")

tabela_rank <- sql("select CODIGO_VAGAO,DIA,  RANK() OVER (PARTITION BY CODIGO_VAGAO ORDER BY DIA desc)  Rank

              from tabela_vagoes_do_pior_trem 
              group by CODIGO_VAGAO,DIA
              order by CODIGO_VAGAO,DIA desc
")

tabela_join <- join(tabela_all, tabela_rank, 
     tabela_all$DIA==tabela_rank$DIA 
     &
    tabela_all$CODIGO_VAGAO==tabela_rank$CODIGO_VAGAO)


tabela_join %>% drop(c("ROW_ID","DATA_HORA_LEITURA","CODIGO_VAGAO","CODIGO_RODEIRO","LADO_RODA","EIXO_VAGAO","CICLO_RODEIRO","SENTIDO_TREM","TRAIN_ID","POSICAO_VAGAO_COMPOSICAO")) %>% head(100) %>% View()

#Foi necessário criar um rank pois as rodas tem medidas em dias diferentes. 

tabela_join %>% drop(c("ROW_ID","DATA_HORA_LEITURA","CODIGO_VAGAO","CODIGO_RODEIRO","LADO_RODA","EIXO_VAGAO","CICLO_RODEIRO","SENTIDO_TREM","TRAIN_ID","POSICAO_VAGAO_COMPOSICAO")) %>% 
  collect() %>% 
  pivot_wider(names_from = c(CODIGO_RODA,Rank),values_from = colunas_numeric$medidas) %>% head(10) %>% View()

```



## Preparação dos Dados

### Particionando os dados 30% para treino e 70% para teste

```{r Divisao_treino_teste}
# Balanceamentos na base (Incluir balanceamentos aqui)

#createOrReplaceTempView(where(df_clean,df_clean$DIA>='2018-08-21'), "final")

createOrReplaceTempView(where(df,df$FRISO_BAIXO==1), "tabela_FRISO_BAIXO")
createOrReplaceTempView(df_clean, "tabela")

sdf_worst_train <- sql("
  
select  TRAIN_ID ,count(*) qtd
       from tabela_FRISO_BAIXO
       group by TRAIN_ID
    order by qtd desc
    limit 100"
    )
head(sdf_worst_train,100)

cod_vagao <- sql("SELECT * 
FROM tabela WHERE TRAIN_ID IN (SELECT TRAIN_ID FROM (select  TRAIN_ID ,count(*) qtd
       from tabela_FRISO_BAIXO
       group by TRAIN_ID
    order by qtd desc
    limit 100))")
dim(cod_vagao)

df_final <- cod_vagao


# Dividindo entre treino e teste

df_list <- randomSplit(df_final, c(2,8),2)

df_train <- df_list[[1]]
df_test <- df_list[[2]]

# Base de Treino

print(paste("A base de treino ficou com ",
            dim(df_train)[1],
            " o que equivale  ",
            round((dim(df_train)[1]*100/dim(df_final)[1]),2)," % da base final",sep=""))

createOrReplaceTempView(where(df_train,df_train$FRISO_BAIXO==1), "tabela_train_yes")
createOrReplaceTempView(where(df_train,df_train$FRISO_BAIXO==0), "tabela_train_no")

train_yes <- sql("SELECT COUNT(1) as YES_TRAIN FROM tabela_train_yes ") %>% head(1)
train_no <- sql("SELECT COUNT(1) as NO_TRAIN FROM tabela_train_no ") %>% head(1)

perc_train_yes <- round((train_yes*100)/(train_yes+train_no),2)
paste("O percentual de YES na base treino e de ",perc_train_yes,"% da base final",sep="")

# Base de Teste

print(paste("A base de testes ficou com ",
            dim(df_test)[1],
            " o que equivale a ",
            round((dim(df_test)[1]*100/dim(df_final)[1]),2)," % da base final",sep=""))

createOrReplaceTempView(where(df_test,df_test$FRISO_BAIXO==1), "tabela_test_yes")
createOrReplaceTempView(where(df_test,df_test$FRISO_BAIXO==0), "tabela_test_no")

test_yes <- sql("SELECT COUNT(1) as YES_TEST FROM tabela_test_yes ") %>% head(1)
test_no <- sql("SELECT COUNT(1) as NO_TEST FROM tabela_test_no ") %>% head(1)

perc_test_yes <- round((test_yes*100)/(test_yes+train_no),2)
paste("O percentual de YES na base teste e de ",perc_test_yes,"% da base final",sep="")
```


```{r base_auxiliar, eval=FALSE}
# Dividindo entre treino e teste

createOrReplaceTempView(where(df_clean,df_clean$DIA>='2018-08-21'), "tabela_ultimo_ciclo")
tabela_aux <- sql("select * from tabela_ultimo_ciclo")

df_list_aux <- randomSplit(tabela_aux, c(7,3),2)

df_train_aux <- df_list[[1]]
df_test_aux <- df_list[[2]]

head(df_train_aux)
# Base de Treino

print(paste("A base de treino ficou com ",
            dim(df_train_aux)[1],
            " o que equivale  ",
            round((dim(df_train_aux)[1]*100/dim(df_clean)[1]),2)," % da base limpa",sep=""))

# Base de Teste

print(paste("A base de testes ficou com ",
            dim(df_test_aux)[1],
            " o que equivale a ",
            round((dim(df_test_aux)[1]*100/dim(df_clean)[1]),2)," % da base limpa",sep=""))



```


```{r eval=FALSE, include=FALSE}

df_sample %>% where(.,isNull(.[["ANGULO_FRISO_RODA"]]))%>% head(100) 
df_sample %>% where(.,!isNull(.[["ANGULO_FRISO_RODA"]]))%>% head(100)

grupo_angulo_null <- groupBy(df %>% where(.,isNull(.[["ANGULO_FRISO_RODA"]])), df$CODIGO_RODA)
df2 <- agg(grupo_angulo_null,count = n(df$CODIGO_RODA))
df2 %>% head(1000)
#Algumas rodas nunca tiveram medidas de ângulo
#(5054164RIGHT,0960614RIGHT,6083714RIGHT,0995294RIGHT,5534531LEFT,5519574RIGHT,0867584RIGHT,6346311RIGHT,0809114RIGHT,5599823RIGHT)
# O que fazer nestes casos?


#Exemplo de rodas com falta de dados e uma opção de completar com fill.

cbind(
df %>% 
  where(.,df$CODIGO_RODA %in%
c('0956094RIGHT','6241133RIGHT','0851232RIGHT','7011773RIGHT','0825071RIGHT','5519574RIGHT','5392051LEFT','6395011LEFT','9126664LEFT')) %>% 
  select('Dia','CODIGO_RODA','ANGULO_FRISO_RODA') %>%  
  arrange('CODIGO_RODA','Dia') %>% 
  head(10000)
,

df %>% 
  where(.,df$CODIGO_RODA %in%
c('0956094RIGHT','6241133RIGHT','0851232RIGHT','7011773RIGHT','0825071RIGHT','5519574RIGHT','5392051LEFT','6395011LEFT','9126664LEFT')) %>% 
  arrange('CODIGO_RODA','Dia') %>% 
    select('ANGULO_FRISO_RODA') %>%  
  withColumnRenamed('ANGULO_FRISO_RODA','downup') %>% 
  head(10000) %>% 
  fill('downup', .direction = "downup")

,

df %>% 
  where(.,df$CODIGO_RODA %in%
c('0956094RIGHT','6241133RIGHT','0851232RIGHT','7011773RIGHT','0825071RIGHT','5519574RIGHT','5392051LEFT','6395011LEFT','9126664LEFT')) %>% 
  arrange('CODIGO_RODA','Dia') %>% 
    select('ANGULO_FRISO_RODA') %>%   
  withColumnRenamed('ANGULO_FRISO_RODA','up') %>% 
  head(10000) %>% 
  fill('up', .direction = "up")



,

df %>% 
  where(.,df$CODIGO_RODA %in%
c('0956094RIGHT','6241133RIGHT','0851232RIGHT','7011773RIGHT','0825071RIGHT','5519574RIGHT','5392051LEFT','6395011LEFT','9126664LEFT')) %>% 
  arrange('CODIGO_RODA','Dia') %>% 
    select('ANGULO_FRISO_RODA') %>%  
  withColumnRenamed('ANGULO_FRISO_RODA','down') %>% 
  head(10000) %>% 
  fill('down', .direction = "down")


) %>% View()



df_sample %>% where(.,isNull(.[["ALTURA_FRISO_RODA"]]))%>% head(100) 
df_sample %>% where(.,isNull(.[["ESPESSURA_FRISO_RODA"]]))%>% head(100)
df_sample %>% where(.,isNull(.[["CAVA_RODA"]]))%>% head(100)



# As medidas do TBOGIE parecem falhar pelo mesma razão para todas as medidas.

# ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE       
# ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE      
# TRACKING_POSITION_EIXO_FRONTAL_TRUQUE   
# ROTACAO_EIXO                            
# ALINHAMENTO_ENTRE_EIXOS_(IAM)           
# DESLOCAMENTO_ENTRE_EIXOS_(SHIFT)        
# TRACKING_ERROR_(TE)                     
# SERPENTEAMENTO_(HUNTING)  

#df_sample %>% where(.,isNaN(.[["ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE"]])) %>% head(100) %>% View()
#df_sample %>% where(.,.[["ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE"]]== "")  %>% head(100) %>% View()
#df_sample %>% where(.,.[["ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE"]]== 0)  %>% head(100) %>% View()


```


## Modelagem

### Regressão logística

```{r Modelo_basico_reg_log, cache=TRUE, include=FALSE}
# Modelo básico de regressão logística
#head(df_train)
#colnames(df_train)

# Dividindo entre treino e teste

model_rl <- spark.logit(df_train, FRISO_BAIXO ~ 
                       VELOCIDADE_ENTRADA_TREM+
                       VELOCIDADE_SAIDA_TREM+
                       ANGULO_FRISO_RODA+
                       ALTURA_FRISO_RODA+
                       CAVA_RODA+
                       ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE+
                       ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE+
                       TRACKING_POSITION_EIXO_FRONTAL_TRUQUE+
                       TRACKING_POSITION_EIXO_TRASEIRO_TRUQUE+
                       ROTACAO_EIXO+
                       ALINHAMENTO_ENTRE_EIXOS_IAM+
                       DESLOCAMENTO_ENTRE_EIXOS_SHIFT+
                       TRACKING_ERROR_TE,
                       thresholds = 0.5,
                     regParam = 0.5)

summary(model_rl)

```

### Árvore de decisão

```{r Modelo_basico_random_forest}
model_rf <- spark.randomForest(df_train, FRISO_BAIXO ~ 
                       VELOCIDADE_ENTRADA_TREM+
                       VELOCIDADE_SAIDA_TREM+
                       ANGULO_FRISO_RODA+
                       ALTURA_FRISO_RODA+
                       CAVA_RODA+
                       ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE+
                       ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE+
                       TRACKING_POSITION_EIXO_FRONTAL_TRUQUE+
                       TRACKING_POSITION_EIXO_TRASEIRO_TRUQUE+
                       ROTACAO_EIXO+
                       ALINHAMENTO_ENTRE_EIXOS_IAM+
                       DESLOCAMENTO_ENTRE_EIXOS_SHIFT+
                       TRACKING_ERROR_TE+
                       SERPENTEAMENTO_HUNTING,
                       "classification",
                     numTrees = 10)

summary(model_rf)
```

## Avaliação

### Regressão logística

```{r Avalicao_regressao_logistica, eval=FALSE, cache=TRUE, include=FALSE}
# Modelo básico de regressão logística
fitted_rl <- predict(model_rl, df_test)

createOrReplaceTempView(fitted_rl, "predictions_rl")

#dim(df_test)

correct_rl <- sql("SELECT prediction, FRISO_BAIXO FROM predictions_rl WHERE prediction=FRISO_BAIXO")
#head(correct)

acc_rl = count(correct_rl)/count(fitted_rl)
acc_rl

# Matriz de confusao
conf_matrix <- data.frame()

model_rl_TP <- sql("SELECT COUNT(1) as TRUE_POSITIVE FROM predictions_rl 
                    WHERE FRISO_BAIXO=1 AND prediction=1
                    ") %>% head(1)

#model_rl_TP[1,1]
conf_matrix[1,1] <- model_rl_TP[1,1]

model_rl_FP <- sql("SELECT COUNT(1) as FALSE_POSITIVE FROM predictions_rl 
                    WHERE FRISO_BAIXO=0 AND prediction=1
                    ") %>% head(1)
#model_rl_FP[1,1]
conf_matrix[2,1] <- model_rl_FP[1,1]

model_rl_TN <- sql("SELECT COUNT(1) as TRUE_NEGATIVE FROM predictions_rl 
                    WHERE FRISO_BAIXO=0 AND prediction=0
                    ") %>% head(1)
#model_rl_TN[1,1]
conf_matrix[2,2] <- model_rl_TN[1,1]

model_rl_FN <- sql("SELECT COUNT(1) as FALSE_NEGATIVE FROM predictions_rl 
                    WHERE FRISO_BAIXO=1 AND prediction=0
                    ") %>% head(1)
#model_rl_FN[1,1]
conf_matrix[1,2] <- model_rl_FN[1,1]

colnames(conf_matrix) <- c("PRED_TRUE","PRED_FALSE")
rownames(conf_matrix) <- c("REAL_TRUE","REAL_FALSE")

conf_matrix %>% kable(., format = "html",row.names = T, digits = 2) %>%
kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
```

### Random Forest

```{r Avaliacao_random_forest, eval=FALSE, cache=TRUE, include=FALSE}
# Modelo básico de random forest
fitted_rf <- predict(model_rf, df_test)

createOrReplaceTempView(fitted_rf, "predictions_rf")

correct_rf <- sql("SELECT prediction, FRISO_BAIXO FROM predictions_rl WHERE prediction=FRISO_BAIXO")
acc_rf = count(correct_rf)/count(fitted_rf)
acc_rf

# Matriz de confusao
conf_matrix <- data.frame()

model_rf_TP <- sql("SELECT COUNT(1) as TRUE_POSITIVE FROM predictions_rf 
                    WHERE FRISO_BAIXO=1 AND prediction=1
                    ") %>% head(1)

model_rf_TP[1,1]
conf_matrix[1,1] <- model_rf_TP[1,1]

model_rf_FP <- sql("SELECT COUNT(1) as FALSE_POSITIVE FROM predictions_rf
                    WHERE FRISO_BAIXO=0 AND prediction=1
                    ") %>% head(1)
model_rf_FP[1,1]
conf_matrix[2,1] <- model_rf_FP[1,1]

model_rf_TN <- sql("SELECT COUNT(1) as TRUE_NEGATIVE FROM predictions_rf 
                    WHERE FRISO_BAIXO=0 AND prediction=0
                    ") %>% head(1)
model_rf_TN[1,1]
conf_matrix[2,2] <- model_rf_TN[1,1]

model_rf_FN <- sql("SELECT COUNT(1) as FALSE_NEGATIVE FROM predictions_rf 
                    WHERE FRISO_BAIXO=1 AND prediction=0
                    ") %>% head(1)
model_rf_FN[1,1]
conf_matrix[1,2] <- model_rf_FN[1,1]

colnames(conf_matrix) <- c("PRED_TRUE","PRED_FALSE")
rownames(conf_matrix) <- c("REAL_TRUE","REAL_FALSE")

conf_matrix %>% kable(., format = "html",row.names = T, digits = 2) %>%
kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
```

## Conclusão

Escrever aqui o texto da conclusao

## Testes

```{r Area_de_teste, eval=FALSE, cache=TRUE, include=FALSE}
# Area para realizacao de testes
#colunas_numeric

createOrReplaceTempView(where(df,df$FRISO_MENOR_QUE_26=="YES"), "tabela_FRISO_BAIXO")
createOrReplaceTempView(df_clean, "tabela")

sdf_worst_train <- sql("
  
select  TRAIN_ID ,count(*) qtd
       from tabela_FRISO_BAIXO
       group by TRAIN_ID
    order by qtd desc
    limit 100"
    )
head(sdf_worst_train,100)


total <- sql("SELECT COUNT(*) FROM tabela") %>%  head()
total
yes <- sql("SELECT COUNT(*) FROM tabela WHERE FRISO_BAIXO=1") %>% head()
no <- sql("SELECT COUNT(*) FROM tabela WHERE FRISO_BAIXO=0") %>% head()

cod_vagao <- sql("SELECT * 
FROM tabela WHERE TRAIN_ID IN (SELECT TRAIN_ID FROM (select  TRAIN_ID ,count(*) qtd
       from tabela_FRISO_BAIXO
       group by TRAIN_ID
    order by qtd desc
    limit 100))")
dim(cod_vagao)

yes <- sql("SELECT COUNT(*) FROM cod_vagao WHERE FRISO_BAIXO=1") %>% head()
yes
no <- sql("SELECT COUNT(*) FROM cod_vagao WHERE FRISO_BAIXO=0") %>% head()
no

# Colocar tabela final para teste

df_final_teste <- cod_vagao

# Dividindo entre treino e teste

df_list_teste <- randomSplit(df_final_teste, c(8,2),2)

df_train_teste <- df_list[[1]]
df_test_teste <- df_list[[2]]

model_teste <- spark.logit(df_train, FRISO_BAIXO ~ 
                       VELOCIDADE_ENTRADA_TREM+
                       VELOCIDADE_SAIDA_TREM+
                       ANGULO_FRISO_RODA+
                       ALTURA_FRISO_RODA+
                       CAVA_RODA+
                       ANGULO_ATAQUE_EIXO_FRONTAL_TRUQUE+
                       ANGULO_ATAQUE_EIXO_TRASEIRO_TRUQUE+
                       TRACKING_POSITION_EIXO_FRONTAL_TRUQUE+
                       TRACKING_POSITION_EIXO_TRASEIRO_TRUQUE+
                       ROTACAO_EIXO+
                       ALINHAMENTO_ENTRE_EIXOS_IAM+
                       DESLOCAMENTO_ENTRE_EIXOS_SHIFT+
                       TRACKING_ERROR_TE,
                       thresholds = 0.5,
                     regParam = 0.5)

summary(model_teste)

fitted_rl <- predict(model_teste, df_train)

# Avaiacao

createOrReplaceTempView(fitted_teste, "predictions_teste")

sql("SELECT * FROM predictions_teste") %>% head(10000) %>% View()

sql("SELECT COUNT(1) FROM predictions_teste 
                    WHERE FRISO_BAIXO=1 AND prediction=1
                    ") %>% head(1)

dim(df_test)

correct_rl <- sql("SELECT prediction, FRISO_BAIXO FROM predictions_teste WHERE prediction=FRISO_BAIXO")
#head(correct)

acc_rl = count(correct_rl)/count(fitted_rl)
acc_rl

# Matriz de confusao
conf_matrix <- data.frame()

model_rl_TP <- sql("SELECT COUNT(1) as TRUE_POSITIVE FROM predictions_teste 
                    WHERE FRISO_BAIXO=1 AND prediction=1
                    ") %>% head(1)

#model_rl_TP[1,1]
conf_matrix[1,1] <- model_rl_TP[1,1]

model_rl_FP <- sql("SELECT COUNT(1) as FALSE_POSITIVE FROM predictions_teste 
                    WHERE FRISO_BAIXO=0 AND prediction=1
                    ") %>% head(1)
#model_rl_FP[1,1]
conf_matrix[2,1] <- model_rl_FP[1,1]

model_rl_TN <- sql("SELECT COUNT(1) as TRUE_NEGATIVE FROM predictions_teste 
                    WHERE FRISO_BAIXO=0 AND prediction=0
                    ") %>% head(1)
#model_rl_TN[1,1]
conf_matrix[2,2] <- model_rl_TN[1,1]

model_rl_FN <- sql("SELECT COUNT(1) as FALSE_NEGATIVE FROM predictions_teste 
                    WHERE FRISO_BAIXO=1 AND prediction=0
                    ") %>% head(1)
#model_rl_FN[1,1]
conf_matrix[1,2] <- model_rl_FN[1,1]

colnames(conf_matrix) <- c("PRED_TRUE","PRED_FALSE")
rownames(conf_matrix) <- c("REAL_TRUE","REAL_FALSE")

conf_matrix %>% kable(., format = "html",row.names = T, digits = 2) %>%
kable_styling(bootstrap_options = c("striped","hover","condensed","responsive"))
